{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"L4","authorship_tag":"ABX9TyNgdm70KLsGk4U6CHK3mxUu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Set Up"],"metadata":{"id":"LOEEO0mRjEV0"}},{"cell_type":"code","source":["%%capture\n","import os\n","if \"COLAB_\" not in \"\".join(os.environ.keys()):\n","    !pip install unsloth\n","else:\n","    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n","    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n","    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n","    !pip install --no-deps unsloth"],"metadata":{"id":"j7QykxwxVYJY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","drive_path = os.path.join('drive', 'MyDrive', 'Colab Notebooks', 'Dacon', 'SentenceOrder') # 다른 드라이브에서 사용할 경우, 이 부분만 적절히 수정\n","\n","if drive_path not in sys.path:\n","  sys.path.append(drive_path)\n","from utility import *\n","\n","SEED=42\n","CONFIG_PATH = drive_path + '/config.yaml'\n","\n","set_all_seed(SEED)\n","config = load_config(CONFIG_PATH)"],"metadata":{"id":"weVK_XYDiu6J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test = pd.read_csv(drive_path + '/dataset/test.csv').drop(columns = 'ID')"],"metadata":{"id":"qBIq5OlAjGkS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load the Model and the Tokenizer"],"metadata":{"id":"7-ERl-eQjK3n"}},{"cell_type":"code","source":["model, tokenizer = FastLanguageModel.from_pretrained(\n","  model_name = config['fine_tuned_model_name'], # JuyeopDang/Qwen-3-14B-Sentence-Ordering\n","  max_seq_length = 512,\n","  load_in_4bit = True,\n",")\n","\n","model.eval()\n","FastLanguageModel.for_inference(model)"],"metadata":{"id":"D8g-3lOwjJw2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inference_message = [\n","    {\"role\": \"system\", \"content\": \"You are an expert at understanding the logical flow of sentences. Your task is to arrange four given Korean sentences into a coherent and natural paragraph. Output the ordered sequence of sentence indices, separated by commas. /no_think\"},\n","    {\"role\": \"user\", \"content\": \"Provided Sentences:\\n0. {sentence_0}\\n1. {sentence_1}\\n2. {sentence_2}\\n3. {sentence_3}\"}\n","]\n","\n","inference_chat_template = tokenizer.apply_chat_template(inference_message, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n","print(inference_chat_template)"],"metadata":{"id":"Ckk6npn4jP1E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluate"],"metadata":{"id":"YgYPmpVrjkvB"}},{"cell_type":"code","source":["def evaluation(model, tokenizer, row, chat_template):\n","  # 하나의 테스트 데이터를 모델이 추론\n","\n","  input = tokenizer(\n","      [ formatting_prompts(row, chat_template) ],\n","      return_tensors=\"pt\"\n","  ).to(\"cuda\")\n","\n","  outputs = model.generate(\n","      input_ids=input.input_ids,\n","      attention_mask=input.attention_mask,\n","      eos_token_id=tokenizer.eos_token_id,\n","      max_new_tokens=32,\n","      use_cache=True,\n","      do_sample=False,\n","      temperature=None,\n","      top_p=None,\n","      top_k=None,\n","      min_p=None,\n","      num_beams=1,\n","  )\n","  response = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","  ans = list(map(int, response[0][-10:].split(','))) # 다른 텍스트를 전부 제외한, 순수 정답만 추출한 후 리스트로 변환\n","\n","  return ans"],"metadata":{"id":"vO1ZWvhsv7OK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_submission = pd.read_csv(drive_path + '/dataset/sample_submission.csv')\n","\n","for i, row in tqdm(test.iterrows()):\n","  ans = evaluation(model, tokenizer, row, inference_chat_template)\n","  for j in range(4):\n","    sample_submission.iloc[i, 1 + j] = ans[j]\n","sample_submission.to_csv(drive_path + f'/prediction/final_submission.csv')"],"metadata":{"id":"onVk_olWUx0Q"},"execution_count":null,"outputs":[]}]}